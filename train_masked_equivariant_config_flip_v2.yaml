encoder:
    # marker-agnostic branch
    ma_layers_blocks: [6]
    ma_embedding_dims: [8]
    # pan-marker equivariant branch
    pm_layers_blocks: [2, 2]
    # pm_embedding_dims: [64, 128]
    pm_embedding_dims: [128, 256]
    maximum_frequency: 1
    include_stem: true
    latent_nonlinearity: "none"
    # use_grn: false

    hyperkernel_config:
      embedding_dim: 128
      kernel_size: 1
      padding: 0
      stride: 1
      use_bias: true

decoder:
  decoded_embed_dim: 384
  num_blocks: 1

  hyperkernel_config:
      # embedding_dim == decoded_embed_dim
      kernel_size: 1
      padding: 0
      stride: 1
      use_bias: true

# Data configuration
panel_config: configs/all_panels_config.yaml
tokenizer_config: configs/all_markers_tokenizer.yaml
input_image_size: [113, 113]
num_workers: 8
batch_size: 4

# Training configuration
device: cuda
lr: 1.5e-4
final_lr: 1e-4
weight_decay: 0.0001
gradient_accumulation_steps: 1
epochs: 100
frac_warmup_steps: 0.1
min_channels_frac: 0.75
spatial_masking_ratio: 0.6
fully_masked_channels_max_frac: 0.5
mask_patch_size: 8
from_checkpoint: null
checkpoints_dir: checkpoints
save_checkpoint_freq: 10

# Neptune logging configuration
tags: ['flip-equivariance', 'hyperkernel', 'patch-masking', 'panel-1 data', 'Gaussian NLL', 'Steerable', 'escnn', 'cropped-patches']
run_prefix: 'EquivariantConvnext_v2'
model_type: "EquivariantConvnext"
